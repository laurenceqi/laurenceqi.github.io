---
layout: post
title: 2019W21 memos
categories: [Memos]
tags: [memos]
---

1. Spark vs mr vs flink 

   1. spark RDD文档

      1. rdd分布式的dataset，计算是lazy的

      2. 支持两种操作，Transformation产生新的rdd/Actions给driver返回值

      3. rdd可以cache，默认放在内存，可配，否则每次都重新计算

      4. Shuffle

      5. function closure，说白了就是序列化代码传到executor进程，所以同一份代码跑在不同的进程上

      6. shared variable： Accumulators累加 & BroadcaseVariable 只读广播

      7. 部署，Driver程序运行在本地，or有资源管理器分配一个节点。

         每个应用会有多个executor进程，每个上面有多个task。

         ![](https://spark.apache.org/docs/latest/img/cluster-overview.png)

         8. [spark tuning](https://spark.apache.org/docs/latest/tuning.html)  
            1. 序列化kryo
            2. Java Memoery overhead 
            3. 优先使用原生类型
            4. G1GC
            5. Parallelism，enough partitions？

   2. Spark SQL docs #todo

   3. spark vs flink

      1. [美图文章](https://mp.weixin.qq.com/s/jllAegJMYh_by95FhHt0jA)
      2. spark 微批处理， flink事件处理
      3. spark一批一调度，flink形成执行图，task位置固定
      4. structured stream和flink都支持事件、处理事件和watermark机制，flink额外支持注入事件
      5. 配合kafka都支持exact once， spark用checkpoint、flink用二阶段提交
      6. 背压，spark用listen判断处理速率，flink通过stacktrace判断task堵塞占比

2. Cd 2.0 https://www.continuousdelivery20.com/archives/696 

   ![](https://www.continuousdelivery20.com/wp-content/uploads/2018/09/cd20-roles.png)

3. 高效会议 

   1. 什么时候需要开会？求取共识？
   2. 与会者准备充分，会上直接讨论，比如bezos的memos、逍遥子的捅三刀
   3. [向三星学习如何开会](http://www.mianfeiwucan.org/fileadmin/gongyi/%E5%90%91%E4%B8%89%E6%98%9F%E5%AD%A6%E5%A6%82%E4%BD%95%E5%BC%80%E4%BC%9A.pdf)
   4. 罗伯特议事规则

4. 如何高效能 

   1. 读完了《高效能人士的7个习惯》 #笔记

5. ES docs 

   1. 重新读了部分ES文档，面对深度分页时候的解决方案，scroll或search after

6. kafka docs/ metics / source code，为了解决kafka监控问题，研究了一些。

7. drc循环复制如何避免？ transaction begin add binlog or  gtid 

   